[
["index.html", "Topics in Bayesian Computing 1 Applications of Bayesian Nonparametric Methods 1.1 Problem Statement 1.2 Tools and Setup 1.3 Jupyter Application Files 1.4 Future Research | Notes and Thoughts Towards a STAT946 Final Project 1.5 To Do", " Topics in Bayesian Computing Class of STAT 946, Spring 2020 University of Waterloo 2020-07-02 1 Applications of Bayesian Nonparametric Methods 1.1 Problem Statement The advent of cheap data storage, ubiquitous networks, and fully connected sensing devices brings with it the possibility to control and monitor processes at scale. Statistical learning methods have enjoyed great success in a number of use cases but a major barrier to their widespread adoption across the internet of things lies in the effort required to achieve useful implementations. Take for example anomaly detection. A typical industrial work place might have tens to hundreds of thousands of measured signals - each with its own set of characteristics behaviors and failure modes. Ideally monitoring and control solutions in these contexts need to be generalized to the extent that they can be applied without specific training or dataset for each signal/device type and failure mode. In the following sections we will take a look at using BNP methods for anomaly detection and signal clustering in a set of industrial process variables. The first example will demonstrate single variate anomaly detection, and the second will look at the multivariate case for clustering. 1.2 Tools and Setup 1.2.1 Tools 1.2.1.1 MIT Probcomp The following provides a brief description of the tools we require to perform bnp based anomaly detection. And the following section gives a set of instructions for installing the required environment. The MIT Probabilistic Computing Project has made available probcomp which is a set of libraries written to support the application of artificial intelligence. To perform anomaly detection we will use some of the functionality provided by cgpm, crosscat, and trcrpm. cgpm is a repository of code to support the implementation of Composable Generative Population Models(CGPM). CGPM provide a layer of abstraction that supports model composition and provides avenues for both sampling of random variable and generation of conditional densities. crosscat provides tools for the Bayesian analysis of high dimensional data tables to support efficient sampling and joint distribution estimation via Bayesian network structure learning and nonparametric mixture modelling. crosscat can be used to identify predictive relationships between variables, uncover complex clustering. Both crosscat and cgpm make extensive use of cython and the associated c++ backend. trcrpm is an implementation of Temporally Reweighted Chinese Restaurant Process Mixture Models described in (Saad and Mansinghka 2018). trcrpm makes calls to cgpm and crosscat to provide a modified version of the Chinese Restaurant Process that introduces a time dependency between successive states of the model. 1.2.2 First Time Installation and Setup The following instruction assume the user has root access to a local system running ubuntu 18.04 and a working git installation. crosscat, cgpm, and trcrpm are all implemented in python 2.7 and tested on ubuntu 16.04. The trcrpm repository includes a docker file for a container with all the required dependencies. We make use of this docker file and the jupyter notebook system to create and run a container on a local system from which to access the code required for the application. To install docker, at a console in ubuntu 18.04 run the following: # update the apt cache sudo apt update # install and update certificate support for docker sudo apt install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&quot; # update the apt cache to include the newly added/trusted docker repositories sudo apt update # install docker sudo apt install docker-ce To allow your current non-root user to run docker, and update your user credentials, run the following and enter your your password at the prompt: sudo usermod -aG docker ${USER} su - ${USER} Next clone the bnp_time_series repository in your desired directory: git clone https://github.com/nick-torenvliet/bnp_time_series.git Enter the docker directory: cd docker Create a docker container for the application: docker build --tag bnp_time_series:00.00 . Start the docker container with a shell: docker run -p 8888:8888 -it bnp_time_series:00.00 In the docker container shell clone the bnp_time_series repository: git clone https://github.com/nick-torenvliet/bnp_time_series.git Change directories to the bnp_time_series directory: cd bnp_time_series Activate the python virtual environment: source /venv/bin/activate Start jupyter notebook: jupyter notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root You will get system output that looks something like this: [C 19:59:16.143 NotebookApp] To access the notebook, open this file in a browser: file:///root/.local/share/jupyter/runtime/nbserver-54-open.html Or copy and paste one of these URLs: http://(d59a4f26bf5d or 127.0.0.1):8888/?token=31fa0215191e6636abf09477761404d35484a4614aab4399 Copy the URL and paste it into a browser address bar. Before following the URL, edit it so it is well-formed as the following: http://127.0.0.1:8888/?token=31fa0215191e6636abf09477761404d35484a4614aab4399 You now should have jupyter notebook running in your browser, on the container just created. 1.2.3 Next Time System Startup If youâ€™ve successfully performed all the step in [#installation] and want to come back to the system after shutting down the docker container only the following steps need to be performed. Start the docker container with a shell: docker run -p 8888:8888 -it bnp_time_series:00.00 git clone https://github.com/nick-torenvliet/bnp_time_series.git cd bnp_time_series source /venv/bin/activate jupyter notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root jupyter notebook is now again accessible from the URL provided in the startup output. There are methods to save the container state so that recloning of the repository is not required but that is outside the scope of this document. 1.3 Jupyter Application Files 1.3.1 Jupyer Notebook Code Examples If the steps in [#installation] were successfully followed to completion then the example application code will be available through the links in the jupyter directory tree view. The following sections describe the files, their usage, and possible avenues to use the stub code as a template to investigate other time series datasets. The jupyter files also contain markdown section with detailed descriptions of the code and its use. 1.3.1.1 Jupyter File data_explorer.ipynb In the files section of the running jupyter notebook instance you will find the /data directory which contains the two datasets required for the intended example applications. The file jupyter file data_explorer.ipynb pulls the data and prepares python pickle files for use by the application files. As long as you data is in .csv format, with an integer index beginning at zero, with all missing data interpolated, you can use data_explorer.ipynb as a template to import your own data sets. Your data must be in a .csv format with variable names in the column headers, all missing data backfilled and interpolated as required, and integer indexing starting at \\(0\\). 1.3.1.2 Jupyter File data_prediction.ipynb 1.3.1.3 Jupyter File anomaly_detection.ipynb anomaly_detection.ipynb investigates using the number of states in the inferred model to make conclusions about the incoming data. 1.3.1.4 Jupyter File multivariate_analysis.ipynb 1.4 Future Research | Notes and Thoughts Towards a STAT946 Final Project 1.4.1 Future Research 1.5 To Do Fix anomaly so it is on a limited set of data Fix anomaly prediction so it works with soft linked variable names "]
]
