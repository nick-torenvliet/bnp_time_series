[
["index.html", "Topics in Bayesian Computing 1 The Practical Problem", " Topics in Bayesian Computing Class of STAT 946, Spring 2020 University of Waterloo 2020-07-04 1 The Practical Problem The Internet of Things(IOT) is made possible by the convergence of cheap data storage, ubiquitous networks, and fully connected sensing devices; all commodity items. IOT brings with it the possibility to control and monitor processes at scale. The immediate intuition is to apply statistical learning to leverage and harness the information in this vast trove of data. But though statistical learning methods have enjoyed great success in a number of use cases a major barrier to their widespread adoption across the IOT lies in the effort required to achieve useful implementations. Consider digital signal monitoring and anomaly detection. Automatic identification and warning of abnormal signal indications is a desirable feature for maintainers of large systems. Typically systems have tens or hundreds of thousands of measured signals; a number that is projected to increase dramatically. Deploying anomaly detection at scale across such systems may not be economically efficient. Each signal, or group of signals, may have its own unique set of characteristic behaviors and failure modes. Training a supervised model, or determining and writing the heuristic rules for each is onerous and costly. Maintaining a collection of model and rules would also be prohibitive in terms of the number of skilled staff such an effort would require. Thus scalable signal monitoring and anomaly detection requires general, unsupervised methods with efficient compute. It is only when a solution requires very little treatment on a per signal basis and consumes a modest set of computational resources that the solution will be of benefit to industry. "],
["the-bayesian-inference-problem.html", "2 The Bayesian Inference Problem 2.1 Addressing Scalability 2.2 The TRCRP Method", " 2 The Bayesian Inference Problem 2.1 Addressing Scalability The Temporally Re-weighted Chinese Restaurant Process (TRCRP) (Saad and Mansinghka 2018) is a Bayesian Nonparametric(BNP) method that could effectively address many of the scalability issues related to signal monitoring and anomaly detection. The originators of the method report impressive results with respect to its ability to impute and predict time series data. As the authors report, the chief benefits of the method are its relative accuracy, and that such accuracy is achieved without significant modeling, or consideration of parameters, on a per time series basis. To test these claims, this preliminary investigation made use of the examples provided by the original authors and applied the method to a set of time series from industrial processes. The results provide an intuition for the inner machinations of the TRCRP process and indicate that there may be reason for optimism in terms of its utility. Additionally the results have uncovered a new use case for the method in the context of identifying anomalous signal behavior via state assignment. 2.2 The TRCRP Method BNP based methods such as TRCRP are often used to model data where the dimension of interest may increase with the size of the data set. BNP models allow for an infinite number of possible categories, states, or clusters, according to the context of application. As such it is a possible candidate for the modeling of signals from devices with an unknown, possibly infinite, number of failure modes. Further to this the state attribution, or cluster association, rules these methods utilize are sensitive to the number of data-points already existing in a given state or cluster; unknown or unfamiliar incoming data will tend to not be grouped with familiar data. Again this makes such methods possible candidates for identifying anomalous data points. TRCRP is a temporal extension of the Chinese Restaurant process. Samples from its posterior are distributed according to a Normal distribution, with a Normal-InverseGamma prior. It uses a Markov Chain Monte Carlo processes for sampling, and hyper parameter re-sampling. Unlike the CRP, TRCRP introduces a temporal dependence on the data, relaxing the requirement for exchangeability normally associated with BNP processes. Inference then becomes dependent not only on the current data-point, but also on some previous window of data \\(p\\) samples wide. With \\(D_{tk}:= \\{ \\xx_{t^\\prime-p:t^\\prime-1} \\mid z_{t^\\prime} = k, 1 \\leq t^\\prime \\lt t \\}\\) the collection of previous data points \\(x_t^\\prime\\) assigned to cluster \\(k\\). \\(\\xx_t\\) becomes dependent on \\(\\xx_{t-p:t-1}\\) for some time window of width \\(p\\) by distributing time series data-points \\((x_1,..,x_n)\\) as: \\[ \\begin{align*} &amp;\\{ \\theta \\} \\iid \\pi_\\Theta( \\cdot \\mid \\lambda_F)\\\\ &amp;Pr[z_t = k \\mid \\zz_{1:t-1},\\xx_{t-p:t-1};\\alpha,\\lambda_G] \\quad \\quad (t = 1,2, ...)\\\\ &amp;\\alpha \\begin{cases} n_{tk}G(\\xx_{t-p:t-1};D_{tk},\\lambda_G) &amp; if\\quad 1\\leq k \\leq max(\\zz_{1:t-1})\\\\ \\alpha G(\\xx_{t-p:t-1};\\lambda_G) &amp; if \\quad k = max(\\zz_{1:t-1})+1 \\\\ \\end{cases} \\\\ &amp; x_t \\mid z_t,\\{\\theta_k\\}\\sim F(\\cdot\\mid\\theta_{z_t}) \\tag{2.1}\\\\ \\end{align*} \\] With Normally distributed \\(F\\): \\[ \\begin{align*} &amp;F(x_t\\mid \\mu_k, \\sigma_k) = N(x_t \\mid \\mu_k, \\sigma^2_k) &amp; \\\\ \\end{align*} \\] And Normal-InverseGame prior \\(\\pi_\\Theta\\): \\[ \\begin{align*} \\pi_\\Theta(\\mu_k, \\sigma^2_k\\mid m,V, a,b) = N(\\mu_k\\mid m, \\sigma^2_k V) I G(\\sigma^2_k\\mid a,b)\\\\ \\end{align*} \\] \\(\\theta_k = (\\mu_k, \\sigma^2_k)\\) are the cluster parameters of \\(F\\), and \\(\\lambda_F = (m,V,a,b)\\) the hyper-parameters of prior \\(\\pi_\\Theta\\). References "],
["test-stand-tools-and-setup.html", "3 Test Stand Tools and Setup", " 3 Test Stand Tools and Setup The following sub-sections briefly describe the toolset required to run the investigation code and provide instructions for their installation and usage. 3.0.1 Tools A brief discussion of the relevant tools follow. The tools are widely, and mostly freely, available. 3.0.1.1 MIT ProbComp Useful Links: MIT Probabilistic Computing Project ProbComp Github Repository The MIT Probabilistic Computing Project has made available probcomp which is a set of libraries written to support the application of artificial intelligence. These investigations use some of the functionality provided by cgpm, crosscat, and trcrpm. cgpm is a repository of code to support the implementation of Composable Generative Population Models(CGPM). CGPM provide a layer of abstraction that supports model composition and provides avenues for both sampling of random variable and generation of conditional densities. crosscat provides tools for the Bayesian analysis of high dimensional data tables to support efficient sampling and joint distribution estimation via Bayesian network structure learning and nonparametric mixture modeling. crosscat can be used to identify predictive relationships between variables, and uncover complex clustering. trcrpm is an implementation of Temporally Reweighted Chinese Restaurant Process Mixture Models described in (Saad and Mansinghka 2018). trcrpm makes calls to cgpm and crosscat to provide a nested version of the Chinese Restaurant Process that introduces a time dependency between successive data-points of the model. cgpm, crosscat, and trcrpm make extensive use of cython and the associated gnu c/c++ backend. 3.0.1.2 Python and Tools Useful Links: Python 2.7 cython jupyter python 2.7 is an older version of the very popular python programming language. cgpm, crosscat, and trcrpm are written in python 2.7 which neccesitates its present usage. cython is a superset of the python language that provides a static compiler with c extensions and linkage. cython provides efficient computing for users of python. jupyter is a web-based development environment that is widely used in data science, scientific computing, and machine learning communities to communicate and collaborate. 3.0.1.3 docker Useful Links: docker docker is a popular “platform as a service” container system. docker is used to automate the construction and deployment of specific software bundles and functionality within isolated containers. Docker is useful for abstracting the installation details and process for specific software integration tasks, allowing the user to focus on system usage rather than installation and maintenance. 3.0.1.4 Ubuntu Useful Links: ubuntu ubuntu is a popular open source operating system based on the linux kernel. 3.0.1.5 git Useful Links: git git is a popular distributed version control system. 3.0.2 First Time Installation and Setup crosscat, cgpm, and trcrpm are all implemented in python 2.7 and tested on ubuntu 16.04. The following instruction use docker to build an image with the required software bundled. docker is then used to deploy the image, as a container, from which the investigation code is run. To successfully complete the following instructions requires root access to a local system running ubuntu 18.04 with a working git installation. To install docker, at a console in ubuntu 18.04 run the following: # update the apt cache sudo apt update # install and update certificate support for docker sudo apt install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&quot; # update the apt cache to include the newly added/trusted docker repositories sudo apt update # install docker sudo apt install docker-ce To allow your current non-root user to run docker, and update user credentials, run the following and enter the root password at the prompt: sudo usermod -aG docker ${USER} su - ${USER} Next clone the bnp_time_series repository in some desired directory: git clone https://github.com/nick-torenvliet/bnp_time_series.git Enter the docker directory in the cloned bnp_time_series repository: cd bnp_time_series/docker Create a docker container for the application, monitor system resource usage to ensure the process hasn’t stalled: docker build --tag bnp_time_series:00.00 . Start the docker container with a shell: docker run -p 8888:8888 -it bnp_time_series:00.00 In the docker container shell change directories to the bnp_time_series directory: cd bnp_time_series Activate the python virtual environment: source /venv/bin/activate Start jupyter notebook: jupyter notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root You will get system output that looks something like this: [C 19:59:16.143 NotebookApp] To access the notebook, open this file in a browser: file:///root/.local/share/jupyter/runtime/nbserver-54-open.html Or copy and paste one of these URLs: http://(d59a4f26bf5d or 127.0.0.1):8888/?token=31fa0215191e6636abf09477761404d35484a4614aab4399 Copy the URL and paste it into a browser address bar. Before following the URL, edit it so it is well-formed as the following: http://127.0.0.1:8888/?token=31fa0215191e6636abf09477761404d35484a4614aab4399 You now should have jupyter notebook running in your browser, served from the docker container just created. The investigation notebooks should be visible on a directory tree view in your browser. 3.0.3 Post Installation docker/jupyter Startup If you’ve successfully performed all the steps in the installation instructions and want to come back to the system after shutting down the docker container the following steps need to be performed. From a ubuntu terminal shell, start the docker container with a shell: docker run -p 8888:8888 -it bnp_time_series:00.00 In the docker shell, change directories, activate the python virtual environment, and start jupyter: cd bnp_time_series source /venv/bin/activate jupyter notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root jupyter notebook is now again accessible from the URL provided in its startup output. References "],
["investigation-results.html", "4 Investigation Results", " 4 Investigation Results If the steps in the installation instructions were successfully followed to completion then the investigation code will be available through the links in the jupyter directory tree view. The jupyter files themselves contain detailed commentary on the usage and coding details; they also provide suggestions to use the stub code as a templates to investigate other time series data sets and application. The following describes the results and general conclusions of the investigation into the TRCRP method. Refer to the jupyter notebook files in the bnp_time_series repository(Torenvliet 2020) to walk through the investigations file by file, cell by cell. 4.0.1 investigation_01_univariate_state_assignment.ipynb The first investigation looks at trcrpm state assignment. The data in this investigation is taken from a temperature sensor on an industrial cooling water flow with an anomaly at ~1700 samples. The data was read in the field every two seconds and is re-indexed on the integers \\(0,..,n\\). The anomaly is due to an intermittent failure on corroded contacts in the signal path. The data was incorporated into a trcrpm model and the posterior developed using MCMC sampling. Afterwards the hyper-parameters were resampled in a similar fashion. Figure 4.1: Model state attribution and test data. Unique states are coded to unique colors. Temperature is in degrees Celsius. Figure 4.1 shows graphically the states attributed to data-points in the time series. As can be seen the state assignment clearly illustrates the main body of the embedded anomaly between samples \\(1500\\) and \\(2000\\). This result is attained without any special tuning or treatment of the method on the basis of the data. 4.0.2 investigation_02_multivariate_prediction.ipynb This investigation probes the predictive capabilities of the trcrpm in a multivariate setting. The data used in this investigation are taken from four temperature sensors situated fore and aft of a large tank of water. The data is again indexed on the integers and was read from the field every two seconds. The data are divided into a training set of \\(100\\) samples, and a held back set of \\(50\\) samples used to validate model predictions. Figure 4.2: Posterior predictive draws for investigation 2. Temperature is in degrees Celsius. Figure 4.2 demonstrates the utility of the model in terms of its ability to generate reasonable predictions. The grey regions demark the 5-95% band for the predictions. Again no special tuning was applied to the model generating these results. 4.0.3 investigation_03_multivariate_state_assignment.ipynb The data used in this investigation are the same as is in the first investigation. In this application the data is synthesized by dividing the original series into four separate series. The anomolous behaviour is embedded in the third series d3. In the multivariate case trcrpm uses a mixture to model the series. This investigation shows that there may be some drawbacks to this approach in terms of state assignment and anomaly detection. In particular 4.3 shows that the model appears to provide only one state assignment across the four, largely unrelated, synthetic series. This appears to cloud the anomaly detection demonstrated in the previous example. Figure 4.3: Multivariate state assignment for investigation 3. Temperature is in degrees Celsius. 4.0.4 investigation_04_univariate_streaming_state_assignment.ipynb The data used in this investigation are taken from a cooling water flow rate meter, again read every two seconds. By observation the data set is punctuated with anomalies. To perform this investigation data was incorporated into the trcrpm model in batches of sample size \\(5000\\). To simulate real time streaming, attempts were made to decrease the batch size, however the code-base appeared variously unstable. In some instance errors occurred, in others no state assignments were made. This could be due to any number of reasons, not least of which was the addition of the bokeh library, and associated call-backs for interactive graphing, to the python code. Figure 4.4 shows the results of a multi-day run of the model against incoming dataset batches. The topmost blue trace is the incoming data. On the bottom, the width of each red point demarks a batch of 5000 samples processed, and the vertical magnitude of the point indicates the number of uniques states in the model at the time the batch was processed. The green trace indicates the state attributed to each incoming datapoint – which at this resolution only provides detail regarding the maximum state assigned in the batch. Of note in Figure 4.4 is the burn-in period over the first \\(\\sim2*10E^5\\) samples after which the model state assignments appear to stabilize. Then the one to one correspondence, from samples \\(\\sim2*10E^5\\) to \\(\\sim3.5*10E^5\\), between anomalies in the data stream and strong signals in the green state assignment trace. And then the apparent loss of stability of the model for samples \\(\\gt \\sim 4*10E^5\\). Figure 4.4: Multivariate state assignment in streaming batch updates for investigation 4. The incoming data stream is in blue, the model state assignment in green, total states in the model per batch in red. Flow is in kg/s. To futher investigate the model burn-in time, figure 4.5 highlights another run of the investigation, this time against a dataset with only \\(4*10E^4\\) samples before the first occurence of an anomaly. Despite the shorter burn-in the model appears stable and able to provide a strong signal relative to the incoming anomaly. Figure 4.5: Multivariate state assignment with short burn in prior to first anomaly. Flow is in kg/s. References "],
["summary.html", "5 Summary", " 5 Summary Initial investigations confirm the claims made by the originators of TRCRP. The method was well able to characterize and predict the handful of data-sets we provided it. At times the code did not appear robust to specific choices for initialization; none of which were expressly out of scope due to theoretical limitations. The current code base is difficult to integrate and implement due to its reliance on python 2.7. In a use case not previously suggested there appeared to be success identifying anomalies in time series. However trcrpm models experienced instability when presented with an extended series of anomalies. Unfortunately is unclear as to whether this was due to the requirement for further academic treatment to deal with model instability in specific contexts – or due to the code base requiring re-factoring. Based only on the evidence provided by these investigations there appears to be merit in further pursuing an investigation into the utility of TRCRP for signal monitoring and anomaly detection at scale. The anomaly detection use-case is novel, and ultimately if successful, would be of value in a great many contexts. Given TRCRP provides ideal grounds for signal monitoring and anomaly detection at scale. Ultimately compute will become an issue. Further research might aim to provide a current, robust, and efficient TRCRP implementation. "],
["references.html", "6 References", " 6 References "]
]
