---
title: "Topics in Bayesian Computing"
author: |
  | **Class of STAT 946, Spring 2020**
  | **University of Waterloo**
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: 
  bookdown::gitbook:
    includes:
      in_header: preamble.html
bibliography: [applications.bib]
link-citations: true
---

```{r setup, include = FALSE}
user_link <- function(name, username) {
  paste0("[", name, "](https://github.com/", username, ")")
}
```
# The Practical Problem
The Internet of Things(IOT) is made possible by the convergence of cheap data storage, ubiquitous networks, and fully connected sensing devices; all commodity items.  IOT brings with it the possibility to control and monitor processes at scale.  The immediate intuition is to apply statistical learning to leverage and harness the information in this vast trove of data.  But though statistical learning methods have enjoyed great success in a number of use cases a major barrier to their widespread adoption across the IOT lies in the effort required to achieve useful implementations.  

Consider digital signal monitoring and anomaly detection.  Automatic identification and warning of abnormal signal indications is a desirable feature for maintainers of large systems.  Typically systems have tens or hundreds of thousands of measured signals; a number that is projected to increase dramatically.  Deploying anomaly detection at scale across such systems may not be economically efficient. Each signal, or group of signals, may have its own unique set of characteristic behaviors and failure modes.  Training a supervised model, or determining and writing the heuristic rules for each is onerous and costly.  Maintaining a collection of model and rules would also be prohibitive in terms of the number of skilled staff such an effort would require.

Thus scalable signal monitoring and anomaly detection requires general, unsupervised methods with efficient compute.  It is only when a solution requires very little treatment on a per signal basis and consumes a modest set of computational resources that the solution will be of benefit to industry.  

# The Bayesian Inference Problem
## Addressing Scalability
The Temporally Re-weighted Chinese Restaurant Process (TRCRP) [@saad2018trcrpm] is a Bayesian Nonparametric(BNP) method that could effectively address many of the scalability issues related to signal monitoring and anomaly detection.  The originators of the method report impressive results with respect to its ability to impute and predict time series data.  As the authors report, the chief benefits of the method are its relative accuracy, and that such accuracy is achieved without significant modeling, or consideration of parameters, on a per time series basis.  

To test these claims, this preliminary investigation made use of the examples provided by the original authors and applied the method to a set of time series from industrial processes. The results provide an intuition for the inner machinations of the TRCRP process and indicate that there may be reason for optimism in terms of its utility.  Additionally the results have uncovered a new use case for the method in the context of identifying anomalous signal behavior via state assignment. 

## The TRCRP Method
BNP based methods such as TRCRP are often used to model data where the dimension of interest may increase with the size of the data set. BNP models allow for an infinite number of possible categories, states, or clusters, according to the context of application.  As such it is a possible candidate for the modeling of signals from devices with an unknown, possibly infinite, number of failure modes.  Further to this the state attribution, or cluster association, rules these methods utilize are sensitive to the number of data-points already existing in a given state or cluster; unknown or unfamiliar incoming data will tend to not be grouped with familiar data.  Again this makes such methods possible candidates for identifying anomalous data points. 

TRCRP is a temporal extension of the Chinese Restaurant process.  Samples from its posterior are distributed according to a Normal distribution, with a Normal-InverseGamma prior.  It uses a Markov Chain Monte Carlo processes for sampling, and hyper parameter re-sampling.

Unlike the CRP, TRCRP introduces a temporal dependence on the data, relaxing the requirement for exchangeability normally associated with BNP processes. Inference then becomes dependent not only on the current data-point, but also on some previous window of data $p$ samples wide.  With $D_{tk}:= \{ \xx_{t^\prime-p:t^\prime-1} \mid z_{t^\prime} = k, 1 \leq t^\prime \lt t \}$ the collection of previous data points $x_t^\prime$ assigned to cluster $k$.  $\xx_t$ becomes dependent on $\xx_{t-p:t-1}$ for some time window of width $p$ 
by distributing time series data-points $(x_1,..,x_n)$ as:

$$
\begin{align*}
&\{ \theta \} \iid \pi_\Theta( \cdot \mid \lambda_F)\\
&Pr[z_t = k \mid \zz_{1:t-1},\xx_{t-p:t-1};\alpha,\lambda_G] \quad \quad (t = 1,2, ...)\\
&\alpha      
  \begin{cases}
      n_{tk}G(\xx_{t-p:t-1};D_{tk},\lambda_G) & if\quad 1\leq k \leq max(\zz_{1:t-1})\\
      \alpha G(\xx_{t-p:t-1};\lambda_G) & if \quad k = max(\zz_{1:t-1})+1  \\
  \end{cases} \\
& x_t \mid z_t,\{\theta_k\}\sim F(\cdot\mid\theta_{z_t}) (\#eq:trcrp-def)\\
\end{align*}
$$
With Normally distributed $F$:
$$
\begin{align*}
&F(x_t\mid \mu_k, \sigma_k) = N(x_t \mid \mu_k, \sigma^2_k) & \\
\end{align*}
$$
And Normal-InverseGame prior $\pi_\Theta$:
$$
\begin{align*}
\pi_\Theta(\mu_k, \sigma^2_k\mid m,V, a,b) = N(\mu_k\mid m, \sigma^2_k V) I G(\sigma^2_k\mid a,b)\\
\end{align*}
$$
$\theta_k = (\mu_k, \sigma^2_k)$ are the cluster parameters of $F$, and $\lambda_F = (m,V,a,b)$ the hyper-parameters of prior $\pi_\Theta$.  

# Test Stand Tools and Setup
```{r child="bnp/tools_and_test_stand.Rmd", echo=T}
```

# Investigation Results
```{r child="bnp/investigations.Rmd", echo=T}
```

# Summary
```{r child="bnp/summary.Rmd", echo=T}
```


# References

